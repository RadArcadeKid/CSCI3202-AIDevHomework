{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <a id='top'></a>\n",
    "\n",
    "# CSCI 3202, Fall 2020\n",
    "# Assignment 3\n",
    "# Due: Monday 16 November 2020 by 11:59 PM\n",
    "\n",
    "<br> \n",
    "\n",
    "### Your name: Jacob (Jake) Henson\n",
    "\n",
    "<br> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "import scipy.integrate as integrate\n",
    "from scipy.optimize import minimize\n",
    "import unittest\n",
    "import math \n",
    "import random\n",
    "from math import floor, isclose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 1:  EVIU and EVPI\n",
    "\n",
    "Suppose we have an overwhelming sense of exam déjà vu, and we're going to catch the Buff Bus again.  We want to decide at what time $d$ to go wait for it.  We decide to use the the linear loss function \n",
    "\n",
    "$$L(d,x)=\\begin{cases} \n",
    "\t2(x-d) & x\\geq d \\\\\n",
    "\t4(d-x) & x <d\n",
    "    \t\\end{cases}$$.\n",
    "        \n",
    "As in the exam, we model the Buff Bus arrival times as an exponential random variable $X$ that arrives on average once per hour, so they have probability density function of $f(x)=e^{-x}$ for $x>0$ (note: this has mean of $E_X[x]=1$).\n",
    "\n",
    "The result from the exam was that the *expected loss* of the decision $d$ was:\n",
    "$$E_X[L(d,x)] = \\int_0^d 4(d-x)e^{-x}\\, dx + \\int_d^\\infty 2(x-d)e^{-x}\\, dx$$\n",
    "\n",
    "...we maybe tried to avoid doing that integral and reasoned through it, because often such an integral is messy and may require numerical methods.\n",
    "\n",
    "\n",
    "### (1a)  A Loss function:\n",
    "\n",
    "Create a `ExpectedLoss` object or function that takes as input 3 arguments: \n",
    "    - a decision $d$\n",
    "    - a loss function $L(d,x)$\n",
    "    - a probability density $f(x)$\n",
    "\n",
    "and returns the value of $$E_X[L(d,x)]=\\int_{-\\infty}^\\infty L(d,x) f(x) \\, dx$$.\n",
    "\n",
    "Inside your function, you can and should use the scipy.integrate function with documentation: \n",
    "https://docs.scipy.org/doc/scipy/reference/tutorial/integrate.html.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [],
   "source": [
    "#broken, being dumb\n",
    "def ExpectedLoss(d, loss_f, pd):\n",
    "\n",
    "    ex = integrate.quad(lambda x: (loss_f(d,x) * pd(x)), float('-inf'), float('inf')) \n",
    "    #this is really confusing, I'm not sure I totally know how to do that \n",
    "    return ex\n",
    "\n",
    "#for 1c\n",
    "def ExpectedLossOther(d):\n",
    "    ex1 =  integrate.quad(lambda x: 4*(d-x)*np.exp(-x), 0,  d)[0]\n",
    "    ex2 =  integrate.quad(lambda x: 4*(d-x)*np.exp(-x), d,  float('inf'))[0]\n",
    "    return (ex1 + ex2)\n",
    "    \n",
    "\n",
    "#for 1c, part 3\n",
    "def ExpectedLossOther2(d):\n",
    "    ex1 =  integrate.quad(lambda x: 4*(d-x)*np.exp(-x), 0,  d)\n",
    "    ex2 =  integrate.quad(lambda x: 4*(d-x)*np.exp(-x), d,  float('inf'))\n",
    "    result = (ex1[0] + ex2[0], ex1[1] + ex2[1]) \n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1b) A quick check:\n",
    "Double check that your integrate code is working well on the infinite support of the exponential random variable.  Check that you in fact get $$E[X]=\\int_0^\\infty e^{-x} \\, dx=1$$ from your usage of `integrate` above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.0000000000000002"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def basic_e(x):\n",
    "    result = np.exp(-x)\n",
    "    return result\n",
    "\n",
    "integrate.quad(basic_e, 0, float('inf'))[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1c) Scoring Decisions:\n",
    "Our goal is typically to compare the losses of 3 decision types:\n",
    " - the decision made \"ignoring uncertainty,\" using $d=E[X]$\n",
    " - the decision made with \"perfect information\", using $d=x$\n",
    " - the decision made with uncertainty to minimize loss, the Bayes' decision.\n",
    " \n",
    "1. Use your function in (1a) to compute the expected loss when ignoring uncertainty.\n",
    "\n",
    "2. Use your function in (1a) or reason to compute the expected loss with perfect information.\n",
    "\n",
    "3. Use your function in (1a) to *plot* the expected loss for a fine grid (`linspace`) of $d$ values from 0 to 10.  Given this plot, visually estimate the optimal decision $d$ and it's expected loss."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1., d = E[x] =  8.881784197001252e-16\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fc204039700>,\n",
       " <matplotlib.lines.Line2D at 0x7fc204039820>]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def l(x, d):\n",
    "    if(x >= d):\n",
    "        return (2 * (x-d))\n",
    "    \n",
    "    if(x < d):\n",
    "        return (4 * (d-x))\n",
    "    \n",
    "#1 - d = E[x]\n",
    "#ExpectedLoss(0, l, basic_e)\n",
    "d = integrate.quad(basic_e, 0, float('inf'))[0] #from 1b \n",
    "print(\"1., d = E[x] = \", ExpectedLossOther(d))\n",
    "\n",
    "\n",
    "#2 -  if d = x then the loss function will always return 0 \n",
    "#This is because then there's no randomness, d, and we can look directly at the loss function\n",
    "#I'm having trouble on how to actually show this using the integral function i made tho... \n",
    "#print(\"2., d = x \", ExpectedLossOther2())\n",
    "\n",
    "#3 - linspace \n",
    "values = []\n",
    "for d in range(0, 10):\n",
    "    values.append(ExpectedLossOther2(d))\n",
    "      \n",
    "np.linspace(-10, 10, 2, endpoint=True)\n",
    "plt.plot(values)\n",
    "\n",
    "#based on this, I think that the best value is somewhere around 1?  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1d) Optimizing Decisions:\n",
    "Since the Bayes' decision should be the minimum of the function in (1a), we can use another numeric method in Python to find it exactly!  Check out `scipy.optimize` https://docs.scipy.org/doc/scipy/reference/tutorial/optimize.html and use it to find the Bayes' decision.\n",
    "\n",
    "For convenience, you may restructure your code in (1a) to get the loss function while only $d$ as taken as an input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm really confused on how to do this one... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## (1e) Bigger Losses\n",
    "$$L_l(d,x)=\\begin{cases} \n",
    "\t20(d-x) & x \\leq d \\\\\n",
    "\t200+20(d-x) & x> d \\\\\t\t\n",
    "\t\\end{cases}$$.\n",
    "    \n",
    "Consider instead the loss function above, which contains a large jump at $x=d$.  Use your `ExpectedLoss` and/or `optimize` routines to find the Bayes' decision for the bus-waiting problem in this case, where a large amount of utility is lost as soon as $x>d$ (or we miss the bus).  Does your result here seem intuitive, given the Bayes' decision in parts (1c/1d)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "#I'm really confused on how to do this one... "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Problem 2:  Bayesian network to model heart disease\n",
    "\n",
    "The following Bayesian network is based loosely on a study that examined heart disease risk factors in 167 elderly individuals in South Carolina.  Note that this figure uses Y and N to represent Yes and No, whereas in class we used the equivalent T and F to represent True and False Boolean values.\n",
    "\n",
    "<img src=\"http://www.cs.colorado.edu/~tonyewong/home/resources/hw05_bayesnet_heartdisease.png\" style=\"width: 650px;\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='p1a'></a>\n",
    "\n",
    "### (2a) \n",
    "\n",
    "Create a `BayesNet` object to model this.  Below are the codes for the (conditional) probability `P` function and `BayesNode` class as well, that we used in class on Monday (9 March) to represent the variable nodes and calculate probabilities. You can code this however you want, subject to the following constraints:\n",
    "1. the nodes are represented using the `BayesNode` class and can work with the `P` function for probabilities,\n",
    "1. your `BayesNet` structure keeps track of which nodes are in the Bayes net, as well as\n",
    "1. which nodes are the parents/children of which other nodes.\n",
    "\n",
    "Some *suggested* skeleton codes for a class structure are given. You are free and encouraged to use the code from our in-class notebooks on Bayes Nets and Markov Models. The point of this exercise is to make sure you understand the example from class. The suggestions for methods to implement are in view of the fact that we will need to calculate some probabilities, which is going to require us to `find_node`s and `find_values` that nodes can take on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "## For the sake of brevity...\n",
    "T, F = True, False\n",
    "\n",
    "## From class:\n",
    "def P(var, value, evidence={}):\n",
    "    '''The probability distribution for P(var | evidence), \n",
    "    when all parent variables are known (in evidence)'''\n",
    "    if len(var.parents)==1:\n",
    "        # only one parent\n",
    "        row = evidence[var.parents[0]]\n",
    "    else:\n",
    "        # multiple parents\n",
    "        row = tuple(evidence[parent] for parent in var.parents)\n",
    "    return var.cpt[row] if value else 1-var.cpt[row]\n",
    "\n",
    "## Also from class:\n",
    "class BayesNode:\n",
    "    \n",
    "    def __init__(self, name, parents, values, cpt):\n",
    "        if isinstance(parents, str):\n",
    "            parents = parents.split()\n",
    "            \n",
    "        if len(parents)==0:\n",
    "            # if no parents, empty dict key for cpt\n",
    "            cpt = {(): cpt}\n",
    "        elif isinstance(cpt, dict):\n",
    "            # if there is only one parent, only one tuple argument\n",
    "            if cpt and isinstance(list(cpt.keys())[0], bool):\n",
    "                cpt = {(v): p for v, p in cpt.items()}\n",
    "\n",
    "        self.variable = name\n",
    "        self.parents = parents\n",
    "        self.cpt = cpt\n",
    "        self.values = values\n",
    "        self.children = []\n",
    "        \n",
    "    def __repr__(self):\n",
    "        return repr((self.variable, ' '.join(self.parents)))    \n",
    "\n",
    "    \n",
    "##===============================================##\n",
    "## Suggested codes for a BayesNet class ##\n",
    "##===============================================##\n",
    "\n",
    "class BayesNet:\n",
    "    '''Bayesian network containing only boolean-variable nodes.'''\n",
    "\n",
    "    def __init__(self, nodes):\n",
    "        '''Initialize the Bayes net by adding each of the nodes,\n",
    "        which should be a list BayesNode class objects ordered\n",
    "        from parents to children (`top` to `bottom`, from causes\n",
    "        to effects)'''\n",
    "        self.nodes = []\n",
    "        self.variables = []\n",
    "        for node in nodes:\n",
    "            self.add(node)        \n",
    "\n",
    "                \n",
    "    def add(self, node):\n",
    "        '''Add a new BayesNode to the BayesNet. The parents should all\n",
    "        already be in the net, and the variable itself should not be'''\n",
    "        assert node.variable not in self.variables\n",
    "        assert all((parent in self.variables) for parent in node.parents)\n",
    "        \n",
    "        self.nodes.append(node)\n",
    "        self.variables.append(node.variable)\n",
    "        for parent in node.parents:\n",
    "            self.find_node(parent).children.append(node)\n",
    "        \n",
    "\n",
    "            \n",
    "    def find_node(self, var):\n",
    "        '''Find and return the BayesNode in the net with name `var`'''\n",
    "        \n",
    "        for n in self.nodes:\n",
    "            if n.variable == var:\n",
    "                return n\n",
    "        raise Exception(\"No such variable: {}\".format(var))\n",
    "\n",
    "    \n",
    "\n",
    "        \n",
    "    def find_values(self, var):\n",
    "        '''Return the set of possible values for variable `var`'''\n",
    "        varnode = self.find_node(var)\n",
    "        return varnode.values\n",
    "\n",
    "\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return 'BayesNet({})'.format(self.nodes)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a Bayes net with those nodes and connections\n",
    "SM = BayesNode('SM', '', [T,F], 0.20) #Smoking and alcohol\n",
    "ME = BayesNode('ME', '', [T,F], 0.50) #Moderate Exercise\n",
    "HBP = BayesNode('HBP', ['SM', 'ME'], [T,F], {\n",
    "    (T, T): 0.60, \n",
    "    (T, F): 0.72, \n",
    "    (F, T): 0.33, \n",
    "    (F, F): 0.51}) #high blood pressure\n",
    "Ath = BayesNode('Ath', '', [T,F], 0.53) #Atheroscleroisis\n",
    "FH = BayesNode('FH', '', [T,F], 0.15) #Family History\n",
    "HD = BayesNode('HD', ['HBP', 'Ath', 'FH'], [T,F], {\n",
    "    (T,T,T): 0.92,\n",
    "    (T,T,F): 0.91,\n",
    "    (T,F,T): 0.81,\n",
    "    (T,F,F): 0.77,\n",
    "    (F,T,T): 0.75,\n",
    "    (F,T,F): 0.69,\n",
    "    (F,F,T): 0.38,\n",
    "    (F,F,F): 0.23}) #Heart Disease \n",
    "Ang = BayesNode('Ang', 'HD', [T,F], {\n",
    "    T: 0.85, \n",
    "    F: 0.40}) #Angina Pectoris\n",
    "Rapid = BayesNode('Rapid', 'HD', [T,F], {\n",
    "    T: 0.99, \n",
    "    F: 0.30}) #Rapid heartbeats\n",
    "\n",
    "\n",
    "bayesHeartDisease = BayesNet([SM, ME, HBP, Ath, FH, HD, Ang, Rapid])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tests_Problem2(unittest.TestCase):\n",
    "    def setUp(self):\n",
    "        self.p1 = BayesNode('p1', '', [T,F], 0.3)\n",
    "        self.p2 = BayesNode('p2', '', [T,F], 0.6)\n",
    "        self.c  = BayesNode('c', ['p1', 'p2'], [T,F], {(T,T):0.1, (T,F):0.2, (F,T):0.3, (F,F):0.4})\n",
    "    def test_onenode(self):\n",
    "        self.assertEqual(P(self.p1, T), 0.3)\n",
    "    def test_twonode(self):\n",
    "        self.assertEqual(P(self.c, F, {'p1':T, 'p2':F}), 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "..\n",
      "----------------------------------------------------------------------\n",
      "Ran 2 tests in 0.003s\n",
      "\n",
      "OK\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tests_to_run = unittest.TestSuite()\n",
    "tests_to_run.addTest(Tests_Problem2(\"test_onenode\"))\n",
    "tests_to_run.addTest(Tests_Problem2(\"test_twonode\"))\n",
    "unittest.TextTestRunner().run(tests_to_run)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### (2b)\n",
    "\n",
    "Craft a function `get_prob(X, e, bn)` to return the **normalized** probability distribution of variable `X` in Bayes net `bn`, given the evidence `e`.  That is, return $P(X \\mid e)$. The arguments are:\n",
    "* `X` is some representation of the variable you are querying the probability distribution of. Either a string (the variable name from the `BayesNode` or a `BayesNode` object itself are good options.\n",
    "* `e` is some representation of the evidence your probability is conditioned on. When given an empty argument (or `None`) for `e`, `get_prob` should return the marginal distribution $P(X)$.\n",
    "* `bn` is your `BayesNet` object.\n",
    "\n",
    "You may do this using the `enumeration` algorithm from class (pseudocode is in the book), or by brute force (i.e., use a few `for` loops). Either way, you should be using your `BayesNet` object to keep track of all the nodes and relationships between nodes so your `get_prob` function knows these things.\n",
    "\n",
    "Suggest implementation is below, where we use the `PDF_discrete` class and its associated functions as we did in the Bayes Nets in class notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Solution:\n",
    "\n",
    "class PDF_discrete:\n",
    "    '''Define a discrete probability distribution function.'''\n",
    "\n",
    "    def __init__(self, varname='?', freqs=None):\n",
    "        '''Create a dictionary of values - frequency pairs,\n",
    "        then normalize the distribution to sum to 1.'''\n",
    "        self.prob = {}\n",
    "        self.varname = varname\n",
    "        self.values = []\n",
    "        if freqs:\n",
    "            for (v, p) in freqs.items():\n",
    "                self[v] = p\n",
    "        self.normalize()\n",
    "\n",
    "    def __getitem__(self, value):\n",
    "        '''Given a value, return P[value]'''\n",
    "        try:\n",
    "            return self.prob[value]\n",
    "        except KeyError:\n",
    "            return 0\n",
    "\n",
    "    def __setitem__(self, value, p):\n",
    "        '''Set P[value] = p, input argument if '''\n",
    "        if value not in self.values:\n",
    "            self.values.append(value)\n",
    "        self.prob[value] = p\n",
    "\n",
    "    def normalize(self):\n",
    "        '''Normalize the probability distribution and return it.\n",
    "        If the sum of PDF values is 0, then return a 0'''\n",
    "        total = sum(self.prob.values())\n",
    "        if not isclose(total, 1.0):\n",
    "            for value in self.prob:\n",
    "                self.prob[value] /= total\n",
    "        return self\n",
    "    \n",
    "def extend(s, var, val):\n",
    "    \"\"\"Copy the substitution s and extend it by setting var to val; return copy.\"\"\"\n",
    "    s2 = s.copy()\n",
    "    s2[var] = val\n",
    "    return s2\n",
    "\n",
    "def get_prob(X, e, bn):\n",
    "    '''Return the conditional probability distribution of variable X\n",
    "    given evidence e, from BayesNet bn. [Figure 14.9]'''\n",
    "    Q = PDF_discrete(X)\n",
    "    for xi in bn.find_values(X):\n",
    "        Q[xi] = enumerate_all(bn.variables, extend(e, X, xi), bn)\n",
    "    return Q.normalize()\n",
    "\n",
    "\n",
    "def enumerate_all(variables, e, bn):\n",
    "    '''Return the sum of those entries in P(variables | e{others})\n",
    "    consistent with e, where P is the joint distribution represented\n",
    "    by bn, and e{others} means e restricted to bn's other variables\n",
    "    (the ones other than variables). Parents must precede children in variables.'''\n",
    "    if not variables:\n",
    "        return 1.0\n",
    "    Y, rest = variables[0], variables[1:]\n",
    "    Ynode = bn.find_node(Y)\n",
    "    if Y in e:\n",
    "        # Y in evidence, so we know its value and just multiply\n",
    "        \n",
    "        return P(Ynode, e[Y], e) * enumerate_all(rest, e, bn)\n",
    "    else:\n",
    "        # Y not in evidence so we have to sum (Law of Total Prob.)    \n",
    "        return sum(P(Ynode, y, e) * enumerate_all(rest, extend(e, Y, y), bn)\n",
    "                   for y in bn.find_values(Y))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2c)\n",
    "Use your `get_prob` function to calculate the following probabilities. Print them to the screen and compare to the original Bayes net figure given to make sure the output passes these \"unit tests\".\n",
    "\n",
    "1. The marginal probability of `Family History` is $P(FH=T)=0.15$\n",
    "2. The probability of *not* experiencing `Angina Pectoris`, given `Heart Disease` is observed, is $P(Ang=F \\mid HD=T)=1-0.85=0.15$\n",
    "3. The probability of `High Blood Pressure`, given a person does `Smoke and/or use Alcohol` but does not get `Moderate Exercise`, is $P(HBP=T \\mid Sm=T, ME=F)=0.72$\n",
    "4. The probability of an arbitrary individual having Heart Disease,  P(HD=T)P(HD=T)\n",
    "5. The probability that an individual does not have Heart Disease, given that Rapid Heartbeat was observed,  P(HD=F∣Rapid=T)P(HD=F∣Rapid=T)\n",
    "6. The probability that an individual is a `Smoker/Alcohol User` if they have `Heart Disease`, $P(Sm=T \\mid HD=T)$\n",
    "7. How would you expect the probability in 6. to change if you also know the individual has `High Blood Pressure`?  Verify your hypothesis by calculating the relevant probability."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. Marginal Probability of Family History, P(FH = T) =  0.15\n",
      "2. Probability of not experiences Angina Pectoris, given Heart Disease is observed, P(Ang=F|HD=T) =  0.15\n",
      "3. Probability of High Blood Pressure, given a person does Smoke and/or use Alcohol but does not get Moderate Exercise, is P(HBP=T|Sm=T,ME=F) =  0.72\n",
      "4. The probability of an arbitrary individual having Heart Disease,  P(HD=T) =  0.66\n",
      "5. The probability that an individual does not have Heart Disease, given that Rapid Heartbeat was observed, P(HD=F∣Rapid=T) =  0.34299744\n",
      "6. The probability that an individual is a Smoker/Alcohol User if they have Heart Disease, P(SM=T|HD=T) =  0.22\n",
      "7. The probability that an individual is a Smoker/Alcohol User if they have Heart Disease AND has High Blood Pressure, P(SM=T|HD=T, HBP=T) =  0.28\n",
      "        Proof for 7 = p_HBP_given_smoking, or P(HBP=T | SM = T) =  0.28\n"
     ]
    }
   ],
   "source": [
    "marg_prob_fh = get_prob(X='FH', e={}, bn=bayesHeartDisease)\n",
    "print(\"1. Marginal Probability of Family History, P(FH = T) = \", marg_prob_fh.prob[T]) #passes!\n",
    "\n",
    "not_expect_ang_given_hd = get_prob(X='Ang', e={'HD': T}, bn=bayesHeartDisease)\n",
    "print(\"2. Probability of not experiences Angina Pectoris, given Heart Disease is observed, P(Ang=F|HD=T) = \", round(not_expect_ang_given_hd.prob[F], 2)) #passes!\n",
    "\n",
    "hbp_given_Nsm_me =  get_prob(X='HBP', e={'SM': T, 'ME': F}, bn=bayesHeartDisease)\n",
    "print(\"3. Probability of High Blood Pressure, given a person does Smoke and/or use Alcohol but does not get Moderate Exercise, is P(HBP=T|Sm=T,ME=F) = \", round(hbp_given_Nsm_me.prob[T], 2))\n",
    "\n",
    "\n",
    "prob_hd =  get_prob(X='HD', e={}, bn=bayesHeartDisease)\n",
    "print(\"4. The probability of an arbitrary individual having Heart Disease,  P(HD=T) = \", round(prob_hd.prob[T],2))\n",
    "\n",
    "not_hd_rd = get_prob(X='HD', e={'Rapid': T}, bn=bayesHeartDisease)\n",
    "print(\"5. The probability that an individual does not have Heart Disease, given that Rapid Heartbeat was observed, P(HD=F∣Rapid=T) = \", prob_hd.prob[F])\n",
    "\n",
    "sm_hd = get_prob(X='SM', e={'HD': T}, bn=bayesHeartDisease)\n",
    "print(\"6. The probability that an individual is a Smoker/Alcohol User if they have Heart Disease, P(SM=T|HD=T) = \", round(sm_hd.prob[T], 2))\n",
    "\n",
    "#For 7, it would make sense that the probability of the person smoking would increase if they had both heart disease AND high blood pressure, \n",
    "# since if they have heart disease allready, it's very very very likely they already have high blood pressure\n",
    "# furthermore, if they are smoking and, high blood pressure, it's very likely that they already have heart disease shown below: \n",
    "sm_hd_hbp = get_prob(X='SM', e={'HD': T, 'HBP': T}, bn=bayesHeartDisease)\n",
    "#Proof: \n",
    "print(\"7. The probability that an individual is a Smoker/Alcohol User if they have Heart Disease AND has High Blood Pressure, P(SM=T|HD=T, HBP=T) = \", round(sm_hd_hbp.prob[T], 2))\n",
    "\n",
    "p_HBP_given_smoking = get_prob(X='SM', e={'HBP':T, 'HD':T}, bn=bayesHeartDisease) \n",
    "print(\"        Proof for 7 = p_HBP_given_smoking, or P(HBP=T | SM = T) = \", round(p_HBP_given_smoking.prob[T], 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### (2d)\n",
    "Rather than exact calculations, we can also *simulate* on a Bayesian Network.  Simulate 10000 hypothetical elderly individuals from South Carolina on the given network.  Using logicals, compute the probabilities in numbers (6.) and (7.) of part (2c) and verify that they are approximately equivalent.\n",
    "\n",
    "No API is required here, but your final result should print the empirical (simulated) probabilities next to the exact theoretical results for these two outcomes from (2c)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NEW - Simulated 6.  P(SM=T|HD=T) =  0.21698\n",
      "NEW - Simulated 7.  P(SM=T|HD=T, HBP=T) =  0.27634\n",
      "----\n",
      "ORIGINAL 6.  =  0.22096\n",
      "ORIGINAL 7.  =  0.28205\n"
     ]
    }
   ],
   "source": [
    "#Recommended simulation structure:\n",
    "#Set up same BayesNodes or Conditional Probability Tables as in (2a)\n",
    "\n",
    "#weighted probability matrix ideas found here: https://stackoverflow.com/questions/10803135/weighted-choice-short-and-simple\n",
    "    \n",
    "num_samples = 10000\n",
    "\n",
    "isSmoker = random.choices([T,F], [.20, 0.80], k=num_samples)\n",
    "mod_exer = random.choices([T,F], [0.50, 0.50], k=num_samples)\n",
    "ath_list = random.choices([T,F], [0.53, 0.47], k=num_samples)\n",
    "fh_list = random.choices([T,F], [0.15, 0.85], k=num_samples)\n",
    "\n",
    "hbp_list = []\n",
    "hd_list = []\n",
    "\n",
    "#populate HBP list \n",
    "for i in range(num_samples): \n",
    "    if(isSmoker[i] == T): #if smoker\n",
    "        if(mod_exer[i] == T): #if exerciser\n",
    "            hbp_list.append(random.choices([T,F], [.60, 0.40])[0])\n",
    "        else:  #if NOT exerciser\n",
    "            hbp_list.append(random.choices([T,F], [0.72, 0.28])[0])\n",
    "    else: #if not smoker \n",
    "        if(mod_exer[i] == T): #if exerciser\n",
    "            hbp_list.append(random.choices([T,F], [.33, 0.67])[0])\n",
    "        else: #if NOT exerciser\n",
    "            hbp_list.append(random.choices([T,F], [.51, 0.49])[0])\n",
    "                   \n",
    "\n",
    "            \n",
    "#Now find heart disease \n",
    "for i in range(num_samples):\n",
    "    if(hbp_list[i] and ath_list[i] and fh_list[i]):\n",
    "        hd_list.append(random.choices([T,F], [.92, 0.08])[0])\n",
    "    elif(hbp_list[i] and ath_list[i] and not fh_list[i]):\n",
    "        hd_list.append(random.choices([T,F], [.91, 0.09])[0])\n",
    "    elif(hbp_list[i] and not ath_list[i] and fh_list[i]):\n",
    "        hd_list.append(random.choices([T,F], [.81, 0.19])[0])\n",
    "    elif(hbp_list[i] and not ath_list[i] and not fh_list[i]):\n",
    "        hd_list.append(random.choices([T,F], [.77, 0.23])[0])\n",
    "    elif(not hbp_list[i] and ath_list[i] and fh_list[i]):\n",
    "        hd_list.append(random.choices([T,F], [.75, 0.25])[0])        \n",
    "    elif(not hbp_list[i] and ath_list[i] and not fh_list[i]):\n",
    "        hd_list.append(random.choices([T,F], [.69, 0.31])[0])  \n",
    "    elif(not hbp_list[i] and not ath_list[i] and fh_list[i]):\n",
    "        hd_list.append(random.choices([T,F], [.38, 0.62])[0]) \n",
    "    else:\n",
    "        hd_list.append(random.choices([T,F], [.23, 0.77])[0]) \n",
    "        \n",
    "\n",
    "\n",
    "p_sm_given_hd = 0 #P(SM=T|HD=T) \n",
    "p_sm_given_hd_hbp_sim = 0 # P(SM=T|HD=T, HBP=T)\n",
    "total_hbp_hd = 0 \n",
    "#NOW PRINT FINAL RESULTS \n",
    "for i in range(num_samples):\n",
    "    if(hd_list[i] and isSmoker[i]): #if they're a smoker and have heart disease\n",
    "            p_sm_given_hd += 1 \n",
    "            \n",
    "    if(hbp_list[i] and isSmoker[i] and hd_list[i]): #if they're a smoker, has heart diease, and has high blood pressure \n",
    "            p_sm_given_hd_hbp_sim += 1\n",
    "                \n",
    "    if(hbp_list[i] and hd_list[i]): #if they have high blood pressure and heart disease\n",
    "            total_hbp_hd += 1\n",
    "            \n",
    "        \n",
    "    \n",
    "p_6_sim =  p_sm_given_hd/sum(hd_list)   \n",
    "p7_sim = p_sm_given_hd_hbp_sim/total_hbp_hd\n",
    "\n",
    "\n",
    "print(\"NEW - Simulated 6.  P(SM=T|HD=T) = \", round(p_6_sim,5)) \n",
    "print(\"NEW - Simulated 7.  P(SM=T|HD=T, HBP=T) = \", round(p7_sim,5))\n",
    "print(\"----\")\n",
    "print(\"ORIGINAL 6.  = \", round(sm_hd.prob[T], 5))\n",
    "print(\"ORIGINAL 7.  = \", round(sm_hd_hbp.prob[T], 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Overall, these results were very very similar with only extremely slight variations! Shown above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
